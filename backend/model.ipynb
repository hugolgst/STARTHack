{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5edc29c2ed010d6458d71a83433b383a96a8cbd3efe8531bc90c4b8a5b8bcec9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model training\n",
    "Using a neural network for the recommender system"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as Functional\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id        type    description  \\\n",
       "0   0       sport       climbing   \n",
       "1   1       sport      badminton   \n",
       "2   2       sport  swimming pool   \n",
       "3   3       sport       climbing   \n",
       "4   4  meditation           yoga   \n",
       "\n",
       "                                                 url  lattitude  longitude  \\\n",
       "0  https://www.facebook.com/groups/escaladeromand...  46.512947   6.624772   \n",
       "1                   http://www.badmintonlausanne.ch/  46.528290   6.601945   \n",
       "2  https://www.lausanne-tourisme.ch/fr/decouvrir/...  46.522474   6.605101   \n",
       "3                               https://totem.ch/?ec  46.516749   6.548327   \n",
       "4                https://totem.ch/yoga#studio?smooth  46.516749   6.548327   \n",
       "\n",
       "   score  \n",
       "0      1  \n",
       "1      4  \n",
       "2      3  \n",
       "3      4  \n",
       "4      4  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>type</th>\n      <th>description</th>\n      <th>url</th>\n      <th>lattitude</th>\n      <th>longitude</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>sport</td>\n      <td>climbing</td>\n      <td>https://www.facebook.com/groups/escaladeromand...</td>\n      <td>46.512947</td>\n      <td>6.624772</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>sport</td>\n      <td>badminton</td>\n      <td>http://www.badmintonlausanne.ch/</td>\n      <td>46.528290</td>\n      <td>6.601945</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>sport</td>\n      <td>swimming pool</td>\n      <td>https://www.lausanne-tourisme.ch/fr/decouvrir/...</td>\n      <td>46.522474</td>\n      <td>6.605101</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>sport</td>\n      <td>climbing</td>\n      <td>https://totem.ch/?ec</td>\n      <td>46.516749</td>\n      <td>6.548327</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>meditation</td>\n      <td>yoga</td>\n      <td>https://totem.ch/yoga#studio?smooth</td>\n      <td>46.516749</td>\n      <td>6.548327</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "activites = pd.read_csv('activities.csv')\n",
    "activites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id  item_id  rating   timestamp\n",
       "0        1        0       2  1616193271\n",
       "2        1        2       0  1616193911\n",
       "1        1        1       1  1616194035\n",
       "3        1        3       0  1616194210\n",
       "4        0        2       2  1616194210"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1616193271</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1616193911</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1616194035</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1616194210</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1616194210</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read the CSV of interactions and sort it by timestamp\n",
    "data = pd.read_csv('interactions.csv')\n",
    "data_sorted = data.sort_values('timestamp')\n",
    "data_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((6, 4), (3, 4))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Cut the data off at 75% in order to save some data for the test process\n",
    "CUTOFF = 0.70\n",
    "cutoff_idx = int(len(data_sorted) * CUTOFF)\n",
    "\n",
    "# Generate the train and test data\n",
    "data_train = data_sorted.iloc[0:cutoff_idx]\n",
    "data_test = data_sorted.iloc[cutoff_idx:]\n",
    "\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "def get_intersection_test_and_train(field):\n",
    "    \"\"\"\n",
    "    Get interactions between the test and train datasets\n",
    "    for the given field\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        set(data_test[field].unique())\n",
    "        & set(data_train[field].unique())\n",
    "    )\n",
    "\n",
    "\n",
    "# Get the interactions between test and train for user_id and item_id\n",
    "interactions_user, intractions_item = get_intersection_test_and_train('user_id'), get_intersection_test_and_train('item_id')\n",
    "\n",
    "# Clean the test dataset to make sure it does not contain \"solo\" data\n",
    "data_test_clean = (\n",
    "    data_test.loc[\n",
    "        data_test['user_id'].isin(interactions_user)\n",
    "        & data_test['item_id'].isin(intractions_item)\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_test_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_test_data_all_in_train(field):\n",
    "    return data_test_clean[field].isin(data_train[field]).all()\n",
    "\n",
    "assert is_test_data_all_in_train('user_id')\n",
    "assert is_test_data_all_in_train('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((6, 4), (3, 4))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def create_mapping_from_data_train(field):\n",
    "    return {elem: i for i, elem in enumerate(data_train[field].unique())}\n",
    "\n",
    "user_to_id, item_to_id = create_mapping_from_data_train('user_id'), create_mapping_from_data_train('item_id')\n",
    "\n",
    "def create_dataset_from_mapping(init_dataset, *fields):\n",
    "    \"\"\"\n",
    "    Returns a clone of the dataset by applying the mappings\n",
    "    created with `create_mapping_from_data_train` on each field\n",
    "    listed in the parameters.  \n",
    "    \"\"\"\n",
    "\n",
    "    mappings = {field: create_mapping_from_data_train(field) for field in fields}\n",
    "\n",
    "    dataset = init_dataset.copy()\n",
    "\n",
    "    for field in fields:\n",
    "        dataset[field] = dataset[field].apply(lambda x: mappings[field][x])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset_train, dataset_test = create_dataset_from_mapping(data_train, 'user_id', 'item_id'), create_dataset_from_mapping(data_test_clean, 'user_id', 'item_id')\n",
    "dataset_train.shape, dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(dataset, x_fields, y_field):\n",
    "    return (\n",
    "        dataset[x_fields].values,\n",
    "        dataset[y_field].values\n",
    "    )\n",
    "\n",
    "X_train, y_train = get_x_y(\n",
    "    dataset_train,\n",
    "    ['user_id', 'item_id'],\n",
    "    'rating'\n",
    ")\n",
    "X_test, y_test = get_x_y(\n",
    "    dataset_test,\n",
    "    ['user_id', 'item_id'],\n",
    "    'rating'\n",
    ")"
   ]
  },
  {
   "source": [
    "## Implement neural network\n",
    "In the following cell I will implemement a neural network instead of a Matrix Factorization to predict the scores for each recommendation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNRecommender(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, hidden_1, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors, sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors, sparse=True)\n",
    "\n",
    "        self.linear_1 = torch.nn.Linear(n_factors*2, hidden_1)\n",
    "        self.linear_2 = torch.nn.Linear(hidden_1, dim_out)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        users_embedding = self.user_factors(user)\n",
    "        items_embedding = self.item_factors(item)\n",
    "\n",
    "        x = torch.cat([\n",
    "            users_embedding,\n",
    "            items_embedding,\n",
    "        ], 1)\n",
    "        h1_relu = Functional.relu(self.linear_1(x))\n",
    "        output = self.linear_2(h1_relu)\n",
    "\n",
    "        return torch.squeeze(output)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                     1.8524170716603596\n"
     ]
    }
   ],
   "source": [
    "model = NNRecommender(\n",
    "    len(data_train['user_id'].unique()),\n",
    "    len(data_train['item_id'].unique()),\n",
    "    20,\n",
    "    20,\n",
    "    1\n",
    ")\n",
    "\n",
    "# Choose the mean squared error as the error function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "# and the Stochastic Gradient Descent as the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "\n",
    "epoch_accumulator = []\n",
    "for epoch in range(10):\n",
    "    # Decide that the size of the batches will be 32\n",
    "    batch_size = 2\n",
    "    split_size = len(X_train) // batch_size\n",
    "\n",
    "    # Split the data in batches\n",
    "    X_batches = np.array_split(X_train, split_size)\n",
    "    y_batches = np.array_split(y_train, split_size)\n",
    "\n",
    "    it = zip(X_batches, y_batches)\n",
    "\n",
    "    loss_accumulator = []\n",
    "\n",
    "    for X, y in tqdm(it, total=len(X_batches), leave=False):\n",
    "        users = X[:, 0]\n",
    "        items = X[:, 1]\n",
    "        ratings = y\n",
    "\n",
    "        ratings = Variable(torch.FloatTensor(ratings))\n",
    "        users = Variable(torch.LongTensor(users))\n",
    "        items = Variable(torch.LongTensor(items))\n",
    "\n",
    "        # Predict the score\n",
    "        predictions = model(users, items)\n",
    "        loss = loss_function(predictions, ratings)\n",
    "\n",
    "        # Executes the back propagation\n",
    "        loss.backward()\n",
    "        # Add the loss value to the accumulator\n",
    "        loss_accumulator.append(loss.detach().numpy())\n",
    "\n",
    "        # finally update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "epoch_accumulator.append(sum(loss_accumulator) / len(X_batches))\n",
    "print(epoch_accumulator[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}